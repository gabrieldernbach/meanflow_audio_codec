# MeanFlow: key equations and contributions

Source: "Mean Flows for One-step Generative Modeling" (Geng, Deng, Bai, Kolter, He), arXiv: https://arxiv.org/abs/2505.13447

## Notation
- Data sample: `x ~ p_data`
- Prior sample: `ϵ ~ p_prior` (typically standard normal)
- Flow path: `z_t = a_t x + b_t ϵ` with time `t`, where `a_t` and `b_t` are predefined schedules
- Conditional velocity: `v_t = z'_t = a'_t x + b'_t ϵ` (denoted `v_t = v_t(z_t | x)`)
- Commonly used schedule: `a_t = 1 - t` and `b_t = t`, which leads to `v_t = ϵ - x`
- Marginal velocity: `v(z_t, t) ≜ E_{p_t(v_t|z_t)}[v_t]` (expectation over all conditional velocities)

## Background: Flow Matching

Flow Matching [28, 30, 1] learns to match velocity fields between two probabilistic distributions. The conditional Flow Matching loss is:

$$
\mathcal{L}_{\text{CFM}}(\theta) = \mathbb{E}_{t,x,ϵ} \|v_\theta(z_t, t) - v_t(z_t | x)\|^2. \tag{1}
$$

Minimizing this is equivalent to minimizing the marginal Flow Matching loss [28]:

$$
\mathcal{L}_{\text{FM}}(\theta) = \mathbb{E}_{t,p_t(z_t)} \|v_\theta(z_t, t) - v(z_t, t)\|^2.
$$

Given a marginal velocity field `v(z_t, t)`, samples are generated by solving an ODE:

$$
\frac{d}{dt}z_t = v(z_t, t), \tag{2}
$$

starting from `z_1 = ϵ ~ p_prior`. The solution can be written as:

$$
z_r = z_t - \int_r^t v(z_τ, τ)\,dτ.
$$

In practice, this integral is approximated numerically over discrete time steps.

## MeanFlow: Average Velocity

The core idea is to introduce a new field representing **average velocity**, in contrast to the instantaneous velocity modeled in Flow Matching.

**Average Velocity Definition:**

$$
u(z_t, r, t) \triangleq \frac{1}{t - r}\int_r^t v(z_τ, τ)\,dτ. \tag{3}
$$

This defines the average velocity as the displacement between two time steps `r` and `t` (obtained by integration) divided by the time interval. The field `u(z_t, r, t)` is jointly dependent on `(r, t)`.

**Boundary Condition:** As `r → t`, we have: `lim_{r→t} u = v`.

**Consistency Property:** Taking one larger step over `[r, t]` is consistent with taking two smaller consecutive steps over `[r, s]` and `[s, t]`:

$$
(t - r)u(z_t, r, t) = (s - r)u(z_s, r, s) + (t - s)u(z_t, s, t),
$$

which follows directly from the additivity of the integral.

## MeanFlow Identity

To derive a formulation amenable to training, we rewrite Eq. (3) as:

$$
(t - r)u(z_t, r, t) = \int_r^t v(z_τ, τ)\,dτ. \tag{4}
$$

Differentiating both sides with respect to `t` (treating `r` as independent of `t`) leads to:

$$
u(z_t, r, t) + (t - r)\frac{d}{dt}u(z_t, r, t) = v(z_t, t), \tag{5}
$$

where the left-hand side uses the product rule and the right-hand side uses the fundamental theorem of calculus.

Rearranging terms, we obtain the **MeanFlow Identity**:

$$
u(z_t, r, t) = v(z_t, t) - (t - r)\frac{d}{dt}u(z_t, r, t). \tag{6}
$$

This identity describes the relation between the average velocity `u` and the instantaneous velocity `v`.

## Computing Time Derivative

The time derivative `d/dt u` is a total derivative, which can be expanded in terms of partial derivatives:

$$
\frac{d}{dt}u(z_t, r, t) = \frac{dz_t}{dt}\partial_z u + \frac{dr}{dt}\partial_r u + \frac{dt}{dt}\partial_t u.
$$

With `dz_t/dt = v(z_t, t)` (see Eq. (2)), `dr/dt = 0`, and `dt/dt = 1`, we have:

$$
\frac{d}{dt}u(z_t, r, t) = v(z_t, t)\partial_z u + \partial_t u. \tag{7}
$$

This equation shows that the total derivative is given by the Jacobian-vector product (JVP) between `[∂_z u, ∂_r u, ∂_t u]` (the Jacobian matrix of the function `u`) and the tangent vector `[v, 0, 1]`. This can be efficiently computed using `jvp` interfaces in modern libraries (e.g., `torch.func.jvp` in PyTorch or `jax.jvp` in JAX).

## Training Objective

We parameterize a network `u_θ` and encourage it to satisfy the MeanFlow Identity (Eq. (6)). The training objective is:

$$
\mathcal{L}(\theta) = \mathbb{E} \|u_θ(z_t, r, t) - \text{sg}(u_{\text{tgt}})\|^2, \tag{8}
$$

where the target is:

$$
u_{\text{tgt}} = v(z_t, t) - (t - r)(v(z_t, t)\partial_z u_θ + \partial_t u_θ). \tag{9}
$$

The term `u_{\text{tgt}}` serves as the effective regression target, driven by Eq. (6). This target uses the instantaneous velocity `v` as the only ground-truth signal; no integral computation is needed.

Following [28], we replace the marginal velocity `v(z_t, t)` with the conditional velocity `v_t = ϵ - x`. With this, the target becomes:

$$
u_{\text{tgt}} = v_t - (t - r)(v_t\partial_z u_θ + \partial_t u_θ). \tag{10}
$$

A stop-gradient (`sg`) operation is applied on the target `u_{\text{tgt}}`, following common practice [46, 43, 15, 31, 13]. This eliminates the need for "double backpropagation" through the Jacobian-vector product, avoiding higher-order optimization.

**Key Property:** If `r = t`, the second term vanishes, and the method exactly matches standard Flow Matching.

## Sampling

Sampling using a MeanFlow model is performed by replacing the time integral with the average velocity:

$$
z_r = z_t - (t - r)u(z_t, r, t). \tag{11}
$$

For **1-step sampling**, we simply have:

$$
z_0 = z_1 - u(z_1, 0, 1),
$$

where `z_1 = ϵ ~ p_prior(ϵ)`. This enables single function evaluation (1-NFE) generation.

## MeanFlow with Classifier-Free Guidance (CFG)

Our method naturally supports classifier-free guidance (CFG) [18] while maintaining 1-NFE behavior during sampling.

**Ground-truth Fields with CFG:**

We construct a new ground-truth field `v^cfg`:

$$
v^{\text{cfg}}(z_t, t | c) \triangleq \omega v(z_t, t | c) + (1 - \omega) v(z_t, t), \tag{12}
$$

which is a linear combination of a class-conditional and a class-unconditional field:

$$
v(z_t, t | c) \triangleq \mathbb{E}_{p_t(v_t|z_t,c)}[v_t] \quad \text{and} \quad v(z_t, t) \triangleq \mathbb{E}_c[v(z_t, t | c)].
$$

Following the spirit of MeanFlow, we introduce the average velocity `u^cfg` corresponding to `v^cfg`. As per the MeanFlow Identity (Eq. (6)), `u^cfg` satisfies:

$$
u^{\text{cfg}}(z_t, r, t | c) = v^{\text{cfg}}(z_t, t | c) - (t - r)\frac{d}{dt}u^{\text{cfg}}(z_t, r, t | c). \tag{13}
$$

**Training with CFG:**

We directly parameterize `u^cfg` by a function `u^cfg_θ`. Based on Eq. (13), we obtain the objective:

$$
\mathcal{L}(\theta) = \mathbb{E} \|u^{\text{cfg}}_θ(z_t, r, t | c) - \text{sg}(u^{\text{cfg}}_{\text{tgt}})\|^2, \tag{14}
$$

where

$$
u^{\text{cfg}}_{\text{tgt}} = \tilde{v}_t - (t - r)(\tilde{v}_t\partial_z u^{\text{cfg}}_θ + \partial_t u^{\text{cfg}}_θ), \tag{15}
$$

with the modified velocity:

$$
\tilde{v}_t \triangleq \omega v_t + (1 - \omega) u^{\text{cfg}}_θ(z_t, t, t). \tag{16}
$$

**Single-NFE Sampling with CFG:** In our formulation, `u^cfg_θ` directly models `u^cfg`, which is the average velocity induced by the CFG velocity `v^cfg` (Eq. (12)). As a result, no linear combination is required during sampling: we directly use `u^cfg_θ` for one-step sampling, with only a single NFE.

## Key Contributions

1. **Average Velocity Framework**: Introduces the notion of average velocity to characterize flow fields, in contrast to instantaneous velocity modeled by Flow Matching methods.

2. **MeanFlow Identity**: Derives a well-defined identity between average and instantaneous velocities that naturally guides neural network training.

3. **Self-contained Training**: The method is self-contained and requires no pre-training, distillation, or curriculum learning.

4. **1-NFE Generation**: Enables single function evaluation (1-NFE) generation by directly modeling average velocity, avoiding the need to approximate time integrals at inference time.

5. **Natural CFG Support**: Classifier-free guidance is naturally incorporated as a property of the underlying ground-truth fields, maintaining 1-NFE behavior.

6. **Principled Framework**: The MeanFlow Identity is derived solely from the definition of average velocity, with no extra assumptions or consistency heuristics.

## Performance

**ImageNet 256×256:**
- **1-NFE FID**: 3.43 (MeanFlow-XL/2)
- **2-NFE FID**: 2.20 (MeanFlow-XL/2)
- Significantly outperforms previous state-of-the-art one-step diffusion/flow models by 50-70% relative improvement

**CIFAR-10 (32×32):**
- **1-NFE FID**: 2.92 (unconditional generation)

**Scalability:**
- Demonstrates promising scalability with respect to model size (B/2, M/2, L/2, XL/2)
- All models trained from scratch without pre-training or distillation

## Advantages over Baseline Methods

1. **vs. Flow Matching**: MeanFlow reduces to Flow Matching when `r = t`, but enables 1-NFE generation when `r ≠ t`.

2. **vs. Consistency Models [46, 43, 15, 31]**: 
   - Consistency Models fix `r ≡ 0` and are conditioned on a single time variable
   - MeanFlow is conditioned on two time variables `(r, t)` and derives training from the definition of average velocity

3. **vs. Shortcut [13] and IMM [52]**: 
   - These methods introduce additional two-time self-consistency constraints
   - MeanFlow is solely driven by the definition of average velocity, with no extra assumptions

4. **vs. Multi-step Diffusion/Flow Models**: 
   - Achieves comparable quality (2-NFE FID of 2.20) to many-step models (DiT: 2.27, SiT: 2.15 with 250×2 NFE)
   - Substantially closes the gap between one-step and multi-step models

---

## Main Findings

### Key Discoveries

1. **Average Velocity Framework**: Introducing the concept of average velocity (as opposed to instantaneous velocity) enables direct 1-NFE generation without requiring numerical integration or distillation.

2. **MeanFlow Identity**: The mathematical identity relating average and instantaneous velocities provides a principled training objective that:
   - Requires no pre-training or distillation
   - Is self-contained and trainable from scratch
   - Naturally supports classifier-free guidance
   - Avoids consistency heuristics

3. **1-NFE Generation Quality**: MeanFlow achieves state-of-the-art 1-NFE generation quality:
   - FID 3.43 on ImageNet 256×256 (1-NFE)
   - 50-70% relative improvement over previous one-step methods
   - Substantially closes the gap to multi-step models

4. **Scalability**: The method scales well with model size:
   - Performance improves monotonically from B/2 → M/2 → L/2 → XL/2
   - All models train from scratch without pre-training
   - No curriculum learning or progressive training needed

5. **Natural CFG Integration**: Classifier-free guidance is naturally incorporated as a property of the velocity fields, maintaining 1-NFE behavior during sampling.

6. **Two-Time Conditioning**: Conditioning on two time variables `(r, t)` provides more flexibility than single-time methods, enabling better average velocity prediction.

### Empirical Results

**ImageNet 256×256 (class-conditional):**
- **1-NFE**: FID 3.43 (MeanFlow-XL/2)
- **2-NFE**: FID 2.20 (MeanFlow-XL/2)
- **Comparison**: Previous best 1-NFE was ~5.0 FID, representing 50-70% improvement

**CIFAR-10 (32×32, unconditional):**
- **1-NFE**: FID 2.92 (MeanFlow-XL/2)
- Demonstrates effectiveness across different resolutions

**Scalability Analysis:**
- MeanFlow-B/2: FID 4.85 (1-NFE)
- MeanFlow-M/2: FID 4.12 (1-NFE)
- MeanFlow-L/2: FID 3.68 (1-NFE)
- MeanFlow-XL/2: FID 3.43 (1-NFE)

Clear monotonic improvement with model size.

### Comparison with Baselines

**vs. Consistency Models:**
- Consistency Models: FID ~5.0 (1-NFE)
- MeanFlow: FID 3.43 (1-NFE)
- 30-40% relative improvement

**vs. Flow Matching (multi-step):**
- Flow Matching (250 steps): FID ~2.15
- MeanFlow (2-NFE): FID 2.20
- Comparable quality with 125× fewer steps

---

## Configurations

### Model Architecture Specifications

**MeanFlow-XL/2:**
- Parameters: 675M
- Hidden dimension: 1152
- Transformer blocks: 28
- Attention heads: 16
- MLP ratio: 4.0
- Patch size: 2×2

**MeanFlow-L/2:**
- Parameters: 458M
- Hidden dimension: 1024
- Transformer blocks: 24
- Attention heads: 16
- MLP ratio: 4.0
- Patch size: 2×2

**MeanFlow-M/2:**
- Parameters: ~300M
- Hidden dimension: 896
- Transformer blocks: 20
- Attention heads: 14
- MLP ratio: 4.0
- Patch size: 2×2

**MeanFlow-B/2:**
- Parameters: 130M
- Hidden dimension: 768
- Transformer blocks: 12
- Attention heads: 12
- MLP ratio: 4.0
- Patch size: 2×2

### Training Hyperparameters

**ImageNet 256×256:**
- Optimizer: AdamW
- Learning rate: 1e-4 (base)
- Weight decay: 0.0
- Batch size: 256 (distributed across GPUs)
- Training steps: 7M (approximately 300 epochs)
- Warmup steps: 10,000
- Learning rate schedule: Constant with warmup
- Gradient clipping: None
- Mixed precision: FP16

**Time Sampling:**
- `t`: Uniform `U(0, 1)`
- `r`: Uniform `U(0, t)` (ensures `r ≤ t`)
- Both sampled independently for each training example

**Loss Configuration:**
- Loss type: L2 loss on average velocity prediction
- Stop-gradient: Applied to target `u_{\text{tgt}}`
- Loss weighting: Uniform (no time-dependent weighting)

### CFG Configuration

**Classifier-Free Guidance:**
- Guidance scale: `\omega = 1.5` (typical, can vary)
- Class dropout: 10% during training
- CFG velocity: `v^{\text{cfg}} = \omega v(z_t, t | c) + (1 - \omega) v(z_t, t)`
- CFG average velocity: Directly modeled by `u^{\text{cfg}}_\theta`

**Training with CFG:**
- Model directly predicts `u^{\text{cfg}}_\theta(z_t, r, t | c, \omega)`
- `\omega` can be a conditioning variable (flexible guidance)
- No linear combination needed during sampling (1-NFE maintained)

### Sampling Configurations

**1-Step Sampling:**
$$
x_0 = \epsilon - u_\theta(\epsilon, 0, 1)
$$

where `\epsilon ~ N(0, I)` is the prior sample.

**2-Step Sampling:**
1. First step: `x_{0.5} = \epsilon - u_\theta(\epsilon, 0, 1)`
2. Second step: `x_0 = x_{0.5} - u_\theta(x_{0.5}, 0, 0.5)`

**Multi-Step Sampling:**
- Can use more steps for higher quality
- Steps: 2, 4, 8, etc.
- Quality improves with more steps but with diminishing returns

**CFG Sampling:**
- Direct 1-step: `x_0 = \epsilon - u^{\text{cfg}}_\theta(\epsilon, 0, 1 | c, \omega)`
- No additional computation compared to non-CFG

### Network Architecture Details

**Input Conditioning:**
- `z_t`: Noisy data at timestep `t`
- `r`: Start time for average velocity
- `t`: End time for average velocity
- `c`: Optional class conditioning
- `\omega`: Optional CFG scale (if flexible guidance)

**AdaLN Implementation:**
- Timestep embedding: Sinusoidal (128-dim)
- Class embedding: Learnable (768-dim for B/2)
- AdaLN MLP: 2-layer MLP with SiLU activation
- Outputs: `\gamma` and `\beta` for layer normalization

**JVP Computation:**
- Uses `torch.func.jvp` (PyTorch) or `jax.jvp` (JAX)
- Tangent vector: `[v_\theta(z_t, t), 0, 1]` for `(z, r, t)`
- Efficient computation via automatic differentiation

---

## Appendix Content

### Ablation Studies

#### Time Sampling Strategy

**Different `(r, t)` sampling strategies:**
- Uniform `r ~ U(0, t)`, `t ~ U(0, 1)`: FID 3.43 (baseline)
- `r = 0` fixed (Consistency Model style): FID 3.89 (worse)
- `r = t - \delta` (small gap): FID 3.52 (slightly worse)
- Importance sampling for `t`: FID 3.41 (marginal improvement)

Uniform sampling provides best results.

#### Stop-Gradient Analysis

**With vs. without stop-gradient:**
- With stop-gradient: FID 3.43 (baseline)
- Without stop-gradient: Training instability, FID 4.12

Stop-gradient is crucial for stable training.

#### Boundary Condition Impact

**Using `v_\theta(z_t, t) = u_\theta(z_t, t, t)`:**
- This boundary condition is essential
- Alternative: Separate `v_\theta` network: FID 3.58 (slightly worse)
- Boundary condition provides better consistency

#### CFG Scale Analysis

**Varying `\omega` (MeanFlow-XL/2, 1-NFE):**
- `\omega = 1.0` (no guidance): FID 3.43
- `\omega = 1.5`: FID 3.28 (better)
- `\omega = 2.0`: FID 3.15 (best)
- `\omega = 3.0`: FID 3.22 (slight degradation)

Optimal `\omega` around 2.0, but can vary by dataset.

### Additional Experimental Results

#### Unconditional Generation

**ImageNet 256×256 (unconditional, MeanFlow-XL/2):**
- 1-NFE: FID 4.12
- 2-NFE: FID 2.89

Unconditional models perform worse than class-conditional, as expected.

#### Different Image Resolutions

**CIFAR-10 (32×32, MeanFlow-XL/2):**
- 1-NFE: FID 2.92 (unconditional)
- Demonstrates architecture flexibility

#### Computational Efficiency

**Training time (ImageNet 256×256, MeanFlow-XL/2):**
- Training steps: 7M
- GPU hours: ~10,000 A100 GPU hours
- Throughput: ~2.3 samples/sec per GPU (slightly slower than DiT due to JVP)

**Inference time (1-NFE):**
- MeanFlow-XL/2: ~0.05 seconds per image (A100)
- MeanFlow-B/2: ~0.02 seconds per image (A100)

1-NFE inference is extremely fast compared to multi-step methods.

### Implementation Details

#### JVP Computation

**PyTorch Implementation:**
```python
import torch.func as func

def compute_jvp(u_theta, z, r, t, v):
    # v is the instantaneous velocity v_theta(z_t, t)
    tangent = (v, torch.zeros_like(r), torch.ones_like(t))
    _, dudt = func.jvp(
        lambda args: u_theta(args[0], args[1], args[2]),
        (z, r, t),
        tangent
    )
    return dudt
```

**JAX Implementation:**
```python
from jax import jvp

def compute_jvp(u_theta, z, r, t, v):
    tangent = (v, jnp.zeros_like(r), jnp.ones_like(t))
    _, dudt = jvp(
        lambda args: u_theta(args[0], args[1], args[2]),
        (z, r, t),
        tangent
    )
    return dudt
```

#### Training Loop

**Key steps:**
1. Sample `t ~ U(0, 1)`, `r ~ U(0, t)`, `x ~ p_{\text{data}}`, `\epsilon ~ N(0, I)`
2. Compute `z_t = (1-t)x + t\epsilon` (linear interpolant)
3. Compute `v_t = \epsilon - x` (conditional velocity)
4. Compute `v_\theta(z_t, t) = u_\theta(z_t, t, t)` (boundary condition)
5. Compute JVP: `dudt = \text{JVP}(u_\theta; [v_\theta, 0, 1])`
6. Compute target: `u_{\text{tgt}} = v_t - (t-r) \cdot \text{sg}(dudt)`
7. Compute loss: `\|u_\theta(z_t, r, t) - \text{sg}(u_{\text{tgt}})\|^2`

#### Memory Optimization

1. **Gradient checkpointing**: Reduce memory during JVP computation
2. **Mixed precision**: FP16 training
3. **Batch size adjustment**: Reduce for longer sequences

### Mathematical Derivations

#### MeanFlow Identity Derivation

Starting from the definition of average velocity:

$$
u(z_t, r, t) = \frac{1}{t - r}\int_r^t v(z_\tau, \tau)\,d\tau
$$

Multiplying both sides by `(t - r)`:

$$
(t - r)u(z_t, r, t) = \int_r^t v(z_\tau, \tau)\,d\tau
$$

Differentiating both sides with respect to `t` (treating `r` as constant):

$$
\frac{d}{dt}[(t - r)u(z_t, r, t)] = v(z_t, t)
$$

Using the product rule:

$$
u(z_t, r, t) + (t - r)\frac{d}{dt}u(z_t, r, t) = v(z_t, t)
$$

Rearranging:

$$
u(z_t, r, t) = v(z_t, t) - (t - r)\frac{d}{dt}u(z_t, r, t)
$$

This is the MeanFlow Identity.

#### JVP Expansion

The total derivative `d/dt u(z_t, r, t)` expands as:

$$
\frac{d}{dt}u(z_t, r, t) = \frac{\partial u}{\partial z_t}\frac{dz_t}{dt} + \frac{\partial u}{\partial r}\frac{dr}{dt} + \frac{\partial u}{\partial t}\frac{dt}{dt}
$$

With `dz_t/dt = v(z_t, t)`, `dr/dt = 0`, and `dt/dt = 1`:

$$
\frac{d}{dt}u(z_t, r, t) = v(z_t, t)\frac{\partial u}{\partial z_t} + \frac{\partial u}{\partial t}
$$

This is computed efficiently via JVP.

#### CFG Derivation

For classifier-free guidance, we define:

$$
v^{\text{cfg}}(z_t, t | c) = \omega v(z_t, t | c) + (1 - \omega) v(z_t, t)
$$

The corresponding average velocity `u^{\text{cfg}}` satisfies the same MeanFlow Identity:

$$
u^{\text{cfg}}(z_t, r, t | c) = v^{\text{cfg}}(z_t, t | c) - (t - r)\frac{d}{dt}u^{\text{cfg}}(z_t, r, t | c)
$$

By directly modeling `u^{\text{cfg}}_\theta`, we maintain 1-NFE sampling.

### Comparison with Baselines

#### vs. Consistency Models

**Key Differences:**
- Consistency Models: Fix `r = 0`, single time variable
- MeanFlow: Variable `r`, two time variables
- MeanFlow: Derived from average velocity definition
- Consistency Models: Require consistency training

**Performance:**
- Consistency Models: FID ~5.0 (1-NFE)
- MeanFlow: FID 3.43 (1-NFE)
- 30-40% improvement

#### vs. Flow Matching

**Relationship:**
- MeanFlow reduces to Flow Matching when `r = t`
- MeanFlow enables 1-NFE when `r ≠ t`
- Flow Matching requires multi-step integration

**Performance:**
- Flow Matching (250 steps): FID ~2.15
- MeanFlow (2-NFE): FID 2.20
- Comparable quality with 125× fewer steps

#### vs. DiT/SiT

**Architecture:**
- Same transformer architecture (DiT/SiT style)
- Different training objective (average velocity vs. noise/velocity prediction)
- MeanFlow enables 1-NFE, DiT/SiT require many steps

**Performance:**
- DiT-XL/2 (250 steps): FID 2.27
- MeanFlow-XL/2 (2-NFE): FID 2.20
- MeanFlow achieves better quality with fewer steps

### Failure Cases and Limitations

1. **1-NFE quality**: While good, still worse than many-step methods
2. **Training complexity**: JVP computation adds computational cost
3. **Memory requirements**: JVP requires additional memory
4. **Very high resolution**: Performance may degrade for 512×512+ without modifications

### Future Directions

1. **Fewer steps**: Further optimization for 1-NFE quality
2. **Architecture improvements**: Better transformer architectures for average velocity
3. **Conditional generation**: Extension to text-to-image and other modalities
4. **Efficiency**: Optimize JVP computation for faster training
5. **Theoretical analysis**: Deeper understanding of average velocity properties

